<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="recalibratiNN">
<title>Recalibrating the predicitions of an ANN. • recalibratiNN</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Recalibrating the predicitions of an ANN.">
<meta property="og:description" content="recalibratiNN">
<meta property="og:image" content="https://cmusso86.github.io/recalibratiNN/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">recalibratiNN</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/simple_mlp.html">Recalibrating the predicitions of an ANN.</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/cmusso86/recalibratiNN/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Recalibrating the predicitions of an ANN.</h1>
            <h3 data-toc-skip class="subtitle">A visual example of
recalibration using bidimensional data.</h3>
            
      
      <small class="dont-index">Source: <a href="https://github.com/cmusso86/recalibratiNN/blob/HEAD/vignettes/simple_mlp.Rmd" class="external-link"><code>vignettes/simple_mlp.Rmd</code></a></small>
      <div class="d-none name"><code>simple_mlp.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="the-problem">The problem<a class="anchor" aria-label="anchor" href="#the-problem"></a>
</h2>
<p>The calibration of a model can be evaluated by comparing observed
values with their respective estimated conditional (or predictive)
distributions. This evaluation can be conducted globally, examining
overall calibration, or locally, investigating calibration in specific
parts of the covariate space. To better illustrate how the package can
improve a models’s calibration, let’s consider some artificial
examples.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://bdm.unb.br/handle/10483/38504" class="external-link">recalibratiNN</a></span><span class="op">)</span></span></code></pre></div>
<p>In the following example, we are going to recalibrate the predictions
of an artificial neural network (ANN) model to non-linear
heteroscedastic data. First we will simulate some data as follows:</p>
<p>We define the sample size: <span class="math display">\[\begin{equation}
n = 10000
\end{equation}\]</span></p>
<p>The vectors <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are generated from uniform
distributions: <span class="math display">\[\begin{equation}
x_1 \sim \text{Uniform}(-3, 3)
\end{equation}\]</span> <span class="math display">\[\begin{equation}
x_2 \sim \text{Uniform}(-5, 5)
\end{equation}\]</span></p>
<p>We define the function <span class="math inline">\(\mu\)</span> as:
<span class="math display">\[\begin{equation}
\mu(x) = \left| x_1^3 - 50 \sin(x_2) + 30 \right|
\end{equation}\]</span></p>
<p>The response variable <span class="math inline">\(y\)</span> is
generated from a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(20 \left| \frac{x_2}{x_1 + 10} \right|\)</span>:
<span class="math display">\[\begin{equation}
y \sim \mathcal{N}\left(\mu, 20 \left| \frac{x_2}{x_1 + 10}
\right|\right)
\end{equation}\]</span></p>
<p>The code bellow generates the data described above.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span>   <span class="co"># The Answer to the Ultimate Question of Life, The Universe, and Everything</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10000</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span>x1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span>, <span class="op">-</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>           x2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span>, <span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu_fun</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">^</span><span class="fl">3</span> <span class="op">-</span> <span class="fl">50</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> <span class="fl">30</span><span class="op">)</span><span class="op">}</span></span>
<span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">mu_fun</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span>, </span>
<span>           mean <span class="op">=</span> <span class="va">mu</span>, </span>
<span>           sd<span class="op">=</span><span class="fl">20</span><span class="op">*</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">/</span><span class="op">(</span><span class="va">x</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">+</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">split1</span> <span class="op">&lt;-</span> <span class="fl">0.6</span></span>
<span><span class="va">split2</span> <span class="op">&lt;-</span> <span class="fl">0.8</span></span>
<span></span>
<span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">split1</span><span class="op">*</span><span class="va">n</span><span class="op">)</span>,<span class="op">]</span></span>
<span><span class="va">y_train</span> <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">split1</span><span class="op">*</span><span class="va">n</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x_cal</span>  <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="op">(</span><span class="va">split1</span><span class="op">*</span><span class="va">n</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">split2</span><span class="op">)</span>,<span class="op">]</span></span>
<span><span class="va">y_cal</span>  <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="op">(</span><span class="va">split1</span><span class="op">*</span><span class="va">n</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">split2</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x_test</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="op">(</span><span class="va">split2</span><span class="op">*</span><span class="va">n</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="va">n</span>,<span class="op">]</span></span>
<span><span class="va">y_test</span>  <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="op">(</span><span class="va">split2</span><span class="op">*</span><span class="va">n</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="va">n</span><span class="op">]</span></span></code></pre></div>
<p>Now, this toy model was trained using the Keras framework with
TensorFlow backend. The ANN architecture consist of an ANN with 3 hidden
layers with ReLU activation functions and dropout for regularization as
follows:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_nn</span> <span class="op">&lt;-</span> <span class="fu">keras_model_sequential</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_nn</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">layer_dense</span><span class="op">(</span>input_shape<span class="op">=</span><span class="fl">2</span>,</span>
<span>              units<span class="op">=</span><span class="fl">800</span>,</span>
<span>              use_bias<span class="op">=</span><span class="cn">T</span>,</span>
<span>              activation <span class="op">=</span> <span class="st">"relu"</span>,</span>
<span>              kernel_initializer<span class="op">=</span><span class="st">"random_normal"</span>,</span>
<span>              bias_initializer <span class="op">=</span> <span class="st">"zeros"</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">layer_dropout</span><span class="op">(</span>rate <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">layer_dense</span><span class="op">(</span>units<span class="op">=</span><span class="fl">800</span>,</span>
<span>              use_bias<span class="op">=</span><span class="cn">T</span>,</span>
<span>              activation <span class="op">=</span> <span class="st">"relu"</span>,</span>
<span>              kernel_initializer<span class="op">=</span><span class="st">"random_normal"</span>,</span>
<span>              bias_initializer <span class="op">=</span> <span class="st">"zeros"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">layer_dropout</span><span class="op">(</span>rate <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">layer_dense</span><span class="op">(</span>units<span class="op">=</span><span class="fl">800</span>,</span>
<span>              use_bias<span class="op">=</span><span class="cn">T</span>,</span>
<span>              activation <span class="op">=</span> <span class="st">"relu"</span>,</span>
<span>              kernel_initializer<span class="op">=</span><span class="st">"random_normal"</span>,</span>
<span>              bias_initializer <span class="op">=</span> <span class="st">"zeros"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>   <span class="fu">layer_batch_normalization</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">layer_dense</span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span>,</span>
<span>              activation <span class="op">=</span> <span class="st">"linear"</span>,</span>
<span>              kernel_initializer <span class="op">=</span> <span class="st">"zeros"</span>,</span>
<span>              bias_initializer <span class="op">=</span> <span class="st">"zeros"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_nn</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">compile</span><span class="op">(</span>optimizer<span class="op">=</span><span class="fu">optimizer_adam</span><span class="op">(</span> <span class="op">)</span>,</span>
<span>    loss <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_nn</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">fit</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_train</span>, </span>
<span>      y <span class="op">=</span> <span class="va">y_train</span>,</span>
<span>      validation_data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">x_cal</span>, <span class="va">y_cal</span><span class="op">)</span>,</span>
<span>      callbacks <span class="op">=</span> <span class="fu">callback_early_stopping</span><span class="op">(</span></span>
<span>        monitor <span class="op">=</span> <span class="st">"val_loss"</span>,</span>
<span>        patience <span class="op">=</span> <span class="fl">20</span>,</span>
<span>        restore_best_weights <span class="op">=</span> <span class="cn">T</span><span class="op">)</span>,</span>
<span>      batch_size <span class="op">=</span> <span class="fl">128</span>,</span>
<span>      epochs <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">y_hat_cal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model_nn</span>, <span class="va">x_cal</span><span class="op">)</span></span>
<span><span class="va">y_hat_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model_nn</span>, <span class="va">x_test</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="observing-miscalibration">Observing miscalibration<a class="anchor" aria-label="anchor" href="#observing-miscalibration"></a>
</h2>
<p>Now, we can evaluate the calibration of the appropriate functions of
the recalibratiNN package. Firstly, we will calculate the Probability
Integral Transform (PIT) values using the <code>PIT_global</code>
function and visualize them using the <code>gg_PIT_global</code>
function.</p>
<p>We can observe in this graph that, globally, the model shows
significant miscalibration (deviating from a uniform distribution)</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## Global calibrations</span></span>
<span><span class="va">pit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/PIT_global.html">PIT_global</a></span><span class="op">(</span>ycal <span class="op">=</span> <span class="va">y_cal</span>, </span>
<span>                  yhat <span class="op">=</span> <span class="va">y_hat_cal</span>, </span>
<span>                  mse <span class="op">=</span> <span class="va">MSE_cal</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="../reference/gg_PIT_global.html">gg_PIT_global</a></span><span class="op">(</span><span class="va">pit</span><span class="op">)</span></span></code></pre></div>
<p><img src="simple_mlp_files/figure-html/unnamed-chunk-6-1.png" width="700">
A similar conclusion can be drawn when observing the comparison of true
and predicted quantiles.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/gg_CD_global.html">gg_CD_global</a></span><span class="op">(</span><span class="va">pit</span>, </span>
<span>             ycal <span class="op">=</span> <span class="va">y_cal</span>,      <span class="co"># true response of calibration set</span></span>
<span>             yhat <span class="op">=</span> <span class="va">y_hat_cal</span>,  <span class="co"># predictions of calibration set</span></span>
<span>             mse <span class="op">=</span> <span class="va">MSE_cal</span><span class="op">)</span>    <span class="co"># mse from training on calibration set</span></span></code></pre></div>
<p><img src="simple_mlp_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
<p>For comparison, we will also calculate the local PIT values using the
local functions. This is important because the model may be well
calibrated globally but not locally. In other words, it may exhibit
varying or even opposing patterns of miscalibration throughout the
covariate space, which can be compensated for when analyzed
globally.</p>
<p>Here, we can see that the model is miscalibrated differently
according to the regions.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pit_local</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/PIT_local.html">PIT_local</a></span><span class="op">(</span>xcal <span class="op">=</span> <span class="va">x_cal</span>,</span>
<span>                       ycal <span class="op">=</span> <span class="va">y_cal</span>, </span>
<span>                       yhat <span class="op">=</span> <span class="va">y_hat_cal</span>, </span>
<span>                       mse <span class="op">=</span> <span class="va">MSE_cal</span></span>
<span>                       <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="../reference/gg_PIT_local.html">gg_PIT_local</a></span><span class="op">(</span><span class="va">pit_local</span><span class="op">)</span></span></code></pre></div>
<p><img src="simple_mlp_files/figure-html/unnamed-chunk-8-1.png" width="700"></p>
<p>Similarly, we observe the miscalibration in:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/gg_CD_local.html">gg_CD_local</a></span><span class="op">(</span><span class="va">pit_local</span><span class="op">)</span></span></code></pre></div>
<p><img src="simple_mlp_files/figure-html/unnamed-chunk-9-1.png" width="700"></p>
<p>Since this example consists of bidimensional data, we visualize the
calibration of the model on a surface representing the covariate space.
In this graph, we used a 95% Confidence Interval centered on the mean
predicted by the model, with a fixed variance estimated by the Mean
Squared Error (MSE). When the true value falls within the interval, it
is colored greenish; when it falls outside, it is colored red.</p>
<p>The following graph illustrates the original coverage of the model,
which is around 90%. Thus, globally, we observe that the model
underestimates the true uncertainty of the data (90% &lt; 95%). However,
despite the global coverage being approximately 90%, there are specific
regions where the model consistently makes more incorrect predictions
(falling well below the 95% mark), while accurately predicting (100%)
within other regions. Although this last part may initially seem
favorable (more accuracy is typically desirable), it indicates that the
uncertainty of the predictions is not adequately captured by the model
(overestimated) . This highlights the importance of interpreting
predictions probabilistically, considering a distribution rather than
just a point prediction.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">coverage_model</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span></span>
<span>  x1cal <span class="op">=</span> <span class="va">x_test</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>, </span>
<span>  x2cal <span class="op">=</span> <span class="va">x_test</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>,</span>
<span>  y_real <span class="op">=</span> <span class="va">y_test</span>, </span>
<span>  y_hat <span class="op">=</span> <span class="va">y_hat_test</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span><span class="fu">mutate</span><span class="op">(</span>lwr <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">qnorm</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="va">y_hat</span>, <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">MSE_cal</span><span class="op">)</span><span class="op">)</span>,</span>
<span>       upr <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">qnorm</a></span><span class="op">(</span><span class="fl">0.95</span>, <span class="va">y_hat</span>, <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">MSE_cal</span><span class="op">)</span><span class="op">)</span>,</span>
<span>       CI <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">y_real</span> <span class="op">&lt;=</span> <span class="va">upr</span> <span class="op">&amp;</span> <span class="va">y_real</span> <span class="op">&gt;=</span> <span class="va">lwr</span>, </span>
<span>                       <span class="st">"in"</span>,  <span class="st">"out"</span> <span class="op">)</span>,</span>
<span>       coverage <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">CI</span> <span class="op">==</span> <span class="st">"in"</span><span class="op">)</span><span class="op">*</span><span class="fl">100</span>,<span class="fl">1</span><span class="op">)</span> </span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">coverage_model</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">CI</span><span class="op">)</span> <span class="op">|&gt;</span>   </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x1cal</span>, </span>
<span>                 <span class="va">x2cal</span>, </span>
<span>                 color <span class="op">=</span> <span class="va">CI</span><span class="op">)</span>,</span>
<span>             alpha <span class="op">=</span> <span class="fl">0.9</span>,</span>
<span>             size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">+</span></span>
<span>   <span class="fu">labs</span><span class="op">(</span>x<span class="op">=</span><span class="st">"x1"</span> , y<span class="op">=</span><span class="st">"x2"</span>, </span>
<span>        title <span class="op">=</span> <span class="fu">glue</span><span class="op">(</span><span class="st">"Original coverage: {coverage_model$coverage[1]} %"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">scale_color_manual</span><span class="op">(</span><span class="st">"Confidence Interval"</span>,</span>
<span>                     values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"in"</span> <span class="op">=</span> <span class="st">"aquamarine3"</span>, </span>
<span>                                <span class="st">"out"</span> <span class="op">=</span> <span class="st">"steelblue4"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="simple_mlp_files/figure-html/unnamed-chunk-10-1.png" width="700"><span style="color:#DAA520; font-weight:bold; text-decoration:underline;">Note:</span>
this visualization is not part of the recalibratiNN package since it can
only be applied to bidimensional data, which is not typically the case
when adjusting neural networks. This example was used specifically to
demonstrate (mis)calibration visually and to make the concept more
tangible.</p>
</div>
<div class="section level2">
<h2 id="recalibration">Recalibration<a class="anchor" aria-label="anchor" href="#recalibration"></a>
</h2>
<p>The primary function of the recalibratiNN package is recalibrate().
As of July 2024, this function includes one implemented method for
recalibration. The method is thoroughly described in <span class="citation">@torres_2024</span>, with a simplified version
discussed in <span class="citation">@musso_2023</span>. The method can
be applied both globally and locally, with a preference for local
application.The function returns a list that includes, among other
things, recalibrated Monte Carlo samples weighted by the distance
between true and predicted observations.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">recalibrated</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="../reference/recalibrate.html">recalibrate</a></span><span class="op">(</span></span>
<span>    yhat_new <span class="op">=</span> <span class="va">y_hat_test</span>, <span class="co"># predictions of test set</span></span>
<span>    space_cal <span class="op">=</span> <span class="va">x_cal</span>,     <span class="co"># covariates of calibration set</span></span>
<span>    pit_values <span class="op">=</span> <span class="va">pit</span>,      <span class="co"># global pit values calculated earlier.</span></span>
<span>    space_new <span class="op">=</span> <span class="va">x_test</span>,    <span class="co"># covariates of test set</span></span>
<span>    mse <span class="op">=</span> <span class="va">MSE_cal</span>,         <span class="co"># MSE from calibration set</span></span>
<span>    type <span class="op">=</span> <span class="st">"local"</span>,        <span class="co"># type of calibration</span></span>
<span>    p_neighbours <span class="op">=</span> <span class="fl">0.08</span><span class="op">)</span>   <span class="co"># proportion of calibration to use as nearest neighbors</span></span>
<span></span>
<span><span class="va">y_hat_rec</span> <span class="op">&lt;-</span> <span class="va">recalibrated</span><span class="op">$</span><span class="va">y_samples_calibrated_wt</span></span></code></pre></div>
<p>That is it! These new values in <code>y_hat_rec</code> are, by
definition, more calibrated than the original ones. This means that the
uncertainty estimation, although not yet perfect, is better than
before.</p>
<p>Shall we see?</p>
<p>Because we have the true observations, we can observe the PIT-values
densities. This visualization is still not implemented as a function in
the package, so the complete code is given below.</p>
<p>We see that the predictions are more calibrated throughout the
covariate space.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">n_clusters</span> <span class="op">&lt;-</span> <span class="fl">6</span> </span>
<span><span class="va">n_neighbours</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y_hat_test</span><span class="op">)</span><span class="op">*</span><span class="fl">0.08</span></span>
<span></span>
<span></span>
<span><span class="co"># calculating centroids</span></span>
<span><span class="va">cluster_means_cal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/kmeans.html" class="external-link">kmeans</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">n_clusters</span><span class="op">)</span><span class="op">$</span><span class="va">centers</span></span>
<span></span>
<span><span class="va">cluster_means_cal</span> <span class="op">&lt;-</span> <span class="va">cluster_means_cal</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">cluster_means_cal</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span>,<span class="op">]</span></span>
<span></span>
<span>  </span>
<span><span class="co"># finding neighbours</span></span>
<span><span class="va">knn_cal</span> <span class="op">&lt;-</span> <span class="fu">nn2</span><span class="op">(</span><span class="va">x_test</span>, </span>
<span>               <span class="va">cluster_means_cal</span>, </span>
<span>               k <span class="op">=</span> <span class="va">n_neighbours</span><span class="op">)</span><span class="op">$</span><span class="va">nn.idx</span></span>
<span></span>
<span></span>
<span><span class="co"># geting corresponding ys (real and estimated)</span></span>
<span><span class="va">y_real_local</span> <span class="op">&lt;-</span> <span class="fu">map</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">knn_cal</span><span class="op">)</span>,  <span class="op">~</span><span class="va">y_test</span><span class="op">[</span><span class="va">knn_cal</span><span class="op">[</span><span class="va">.</span>,<span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">y_hat_local</span> <span class="op">&lt;-</span> <span class="fu">map</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">knn_cal</span><span class="op">)</span>,  <span class="op">~</span><span class="va">y_hat_rec</span><span class="op">[</span><span class="va">knn_cal</span><span class="op">[</span><span class="va">.</span>,<span class="op">]</span>,<span class="op">]</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># calculate pit_local</span></span>
<span><span class="va">pits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="cn">NA</span>, </span>
<span>               nrow <span class="op">=</span> <span class="fl">6</span>, </span>
<span>               ncol <span class="op">=</span> <span class="va">n_neighbours</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_clusters</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">pits</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">map_dbl</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n_neighbours</span>, <span class="op">~</span><span class="op">{</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y_hat_local</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="va">.</span>,<span class="op">]</span> <span class="op">&lt;=</span> <span class="va">y_hat_local</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="va">.</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="op">}</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">pits</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">pivot_longer</span><span class="op">(</span><span class="fu">everything</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">name</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>p_value <span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/ks.test.html" class="external-link">ks.test</a></span><span class="op">(</span><span class="va">value</span>,</span>
<span>                          <span class="st">"punif"</span><span class="op">)</span><span class="op">$</span><span class="va">p.value</span>,</span>
<span>         name <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/grep.html" class="external-link">gsub</a></span><span class="op">(</span><span class="st">"V"</span>, <span class="st">"part_"</span>, <span class="va">name</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">geom_density</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">value</span>,</span>
<span>                   color <span class="op">=</span> <span class="va">name</span>,</span>
<span>                   fill <span class="op">=</span> <span class="va">name</span><span class="op">)</span>,</span>
<span>               alpha <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>               bounds <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">geom_hline</span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">1</span>, </span>
<span>             linetype<span class="op">=</span><span class="st">"dashed"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">scale_color_brewer</span><span class="op">(</span>palette <span class="op">=</span> <span class="st">"Set2"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">scale_fill_brewer</span><span class="op">(</span>palette <span class="op">=</span> <span class="st">"Set2"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">geom_text</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.5</span>, </span>
<span>                y <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>                label <span class="op">=</span> <span class="fu">glue</span><span class="op">(</span><span class="st">"p-value: {round(p_value, 3)}"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>            color <span class="op">=</span> <span class="st">"black"</span>,</span>
<span>            size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"After Local Calibration"</span>,</span>
<span>       subtitle <span class="op">=</span> <span class="st">"It looks so much better!!"</span>,</span>
<span>       x <span class="op">=</span> <span class="st">"PIT-values"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Density"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">name</span>, scales <span class="op">=</span> <span class="st">"free_y"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: There were 6 warnings in `mutate()`.</span></span>
<span><span class="co">#&gt; The first warning was:</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> In argument: `p_value = ks.test(value, "punif")$p.value`.</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> In group 1: `name = "V1"`.</span></span>
<span><span class="co">#&gt; Caused by warning in `ks.test.default()`:</span></span>
<span><span class="co">#&gt; <span style="color: #BBBB00;">!</span> ties should not be present for the one-sample Kolmogorov-Smirnov test</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Run `dplyr::last_dplyr_warnings()` to see the 5 remaining warnings.</span></span></code></pre></div>
<p><img src="simple_mlp_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
<p>Once again, because we are working with bidimensional data, we can
observe the coverage on a surface. We notice that the global coverage
has improved slightly, and responses that fall within and outside the
confidence interval (CI) are much better distributed (though still not
perfect). Fine-tuning to adjust the number of neighbors may be required,
as it involves a trade-off between localization and Monte Carlo
error.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span> <span class="va">coverage_rec</span> <span class="op">&lt;-</span> <span class="fu">map_dfr</span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">)</span>, <span class="op">~</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile</a></span><span class="op">(</span><span class="va">y_hat_rec</span><span class="op">[</span><span class="va">.</span>,<span class="op">]</span></span>
<span>           ,<span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="fl">0.95</span><span class="op">)</span><span class="op">)</span><span class="op">}</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span></span>
<span>    x1 <span class="op">=</span> <span class="va">x_test</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,</span>
<span>    x2 <span class="op">=</span> <span class="va">x_test</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>,</span>
<span>    ytest <span class="op">=</span> <span class="va">y_test</span>,</span>
<span>    CI <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">ytest</span> <span class="op">&lt;=</span> <span class="va">`95%`</span><span class="op">&amp;</span> <span class="va">ytest</span> <span class="op">&gt;=</span> <span class="va">`5%`</span>, </span>
<span>                <span class="st">"in"</span>, <span class="st">"out"</span><span class="op">)</span>,</span>
<span>    coverage <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">CI</span> <span class="op">==</span> <span class="st">"in"</span><span class="op">)</span><span class="op">*</span><span class="fl">100</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">CI</span><span class="op">)</span></span>
<span></span>
<span> <span class="va">coverage_rec</span> <span class="op">|&gt;</span> </span>
<span>   <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span>, color <span class="op">=</span> <span class="va">CI</span><span class="op">)</span>,</span>
<span>              alpha <span class="op">=</span> <span class="fl">0.9</span>,</span>
<span>              size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">+</span></span>
<span>   <span class="fu">labs</span><span class="op">(</span>x<span class="op">=</span><span class="st">"x1"</span> , y<span class="op">=</span><span class="st">"x2"</span>, </span>
<span>        title <span class="op">=</span> <span class="fu">glue</span><span class="op">(</span><span class="st">"Recalibrated coverage: {coverage_rec$coverage[1]} %"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">scale_color_manual</span><span class="op">(</span><span class="st">"Confidence Interval"</span>,</span>
<span>                     values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"in"</span> <span class="op">=</span> <span class="st">"aquamarine3"</span>, </span>
<span>                                <span class="st">"out"</span> <span class="op">=</span> <span class="st">"steelblue4"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="simple_mlp_files/figure-html/unnamed-chunk-13-1.png" width="700"></p>
<!-- Lastly, we can observe that the point estimates have also improved. Baring in mind that when plotting true vs. estimated mean, we would expect a perfect line if the prediction were equal to the true observation. After calibration, we see that the recalibrated observations are more concentrated around the true mean and less scattered. -->
<p>“In the next example, we are going to recalibrate predictions of a
more complex neural network/data.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Carolina Musso, Ricardo Torres, João Reis, Guilherme Rodrigues.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
